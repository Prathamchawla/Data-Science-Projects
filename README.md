# Data-Science-Projects

This folder contains the projects in which I used a Proper Data Science Pipeline.
Data Science Pipeline:
The Data Science pipeline is a broader concept that encompasses various stages of data analysis, modeling, and deployment. While ETL is a critical part of data preparation within the data science pipeline, the pipeline includes several other steps:

Data Collection: In addition to ETL, data scientists may need to collect new data or access external data sources to augment existing datasets.

Exploratory Data Analysis (EDA): Data scientists often perform EDA to understand the characteristics of the data, identify patterns, outliers, and gain insights. This step helps in feature selection and engineering.

Model Development: This phase involves selecting appropriate machine learning or statistical models, training them on the prepared data, and fine-tuning model parameters.

Model Evaluation: Models are evaluated using various metrics to assess their performance. Cross-validation, holdout sets, and other techniques are used to ensure the model's generalizability.

Model Deployment: Once a satisfactory model is developed, it needs to be deployed in a production environment where it can make predictions on new data.

I started with the data collection and then perfrom the ETL Process with help of Business Intelligence Tools(SSIS(SQL Server Integration Services) and SSMS(SQL Server Managment Studio)).
After completing the ETL process, We can do Analysis and Visualization with help of Power BI and Move towards Modeling.
After Modeling,Model Evaluation is necessary for checking the accuracy of the model.
Once the evaluation is done after that we can create a Web API using Flask and Deploy our Model
--
